{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn as skn  \n",
    "import numpy as np \n",
    "import scipy \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT OF VARIOUS LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING OF THE DATASETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Quality</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal sanitizer. Does its job</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quite sticky, but it does the job</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fits nicely in hand bags etc and reasonably pr...</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We like am well well.</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments      rating\n",
       "0                                      Great Quality  5 out of 5\n",
       "1                     Normal sanitizer. Does its job  4 out of 5\n",
       "2                  quite sticky, but it does the job  5 out of 5\n",
       "3  Fits nicely in hand bags etc and reasonably pr...  4 out of 5\n",
       "4                              We like am well well.  5 out of 5"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GETTING THE STORED DATASET \n",
    "text_data = pd.read_csv(r'C:\\Users\\eking\\Documents\\my B.sc Project\\my datasets\\Review of NOTE 8i(X693).csv') \n",
    "text_data.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning/preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Quality</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal sanitizer. Does its job</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quite sticky, but it does the job</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fits nicely in hand bags etc and reasonably pr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We like am well well.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its ok</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sanitizes and has a nice scent.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Havent used it.\\nWell packaged sha.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smells good too</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's serving well .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments rating\n",
       "0                                      Great Quality    5  \n",
       "1                     Normal sanitizer. Does its job    4  \n",
       "2                  quite sticky, but it does the job    5  \n",
       "3  Fits nicely in hand bags etc and reasonably pr...    4  \n",
       "4                              We like am well well.    5  \n",
       "5                                             its ok    5  \n",
       "6                    Sanitizes and has a nice scent.    5  \n",
       "7                Havent used it.\\nWell packaged sha.    4  \n",
       "8                                    Smells good too    5  \n",
       "9                                It's serving well .    5  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing 'out of 5 ' from the rating to leave the values '4, 5, 3, 2, 1'\n",
    "text_data['rating'] = text_data['rating'].str.replace('out of 5', ' ') \n",
    "text_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal sanitizer. Does its job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quite sticky, but it does the job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fits nicely in hand bags etc and reasonably pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We like am well well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sanitizes and has a nice scent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Havent used it.\\nWell packaged sha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smells good too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's serving well .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments\n",
       "0                                      Great Quality\n",
       "1                     Normal sanitizer. Does its job\n",
       "2                  quite sticky, but it does the job\n",
       "3  Fits nicely in hand bags etc and reasonably pr...\n",
       "4                              We like am well well.\n",
       "5                                             its ok\n",
       "6                    Sanitizes and has a nice scent.\n",
       "7                Havent used it.\\nWell packaged sha.\n",
       "8                                    Smells good too\n",
       "9                                It's serving well ."
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the comments and in another variable ; comments \n",
    "comments = text_data[['comments']]\n",
    "comments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating\n",
       "0    5  \n",
       "1    4  \n",
       "2    5  \n",
       "3    4  \n",
       "4    5  \n",
       "5    5  \n",
       "6    5  \n",
       "7    4  \n",
       "8    5  \n",
       "9    5  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the ratings in another variable ; rating \n",
    "rating = text_data[['rating']] \n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Great Quality'],\n",
       " ['Normal sanitizer. Does its job'],\n",
       " ['quite sticky, but it does the job'],\n",
       " ['Fits nicely in hand bags etc and reasonably priced. \\nGood product.'],\n",
       " ['We like am well well.'],\n",
       " ['its ok'],\n",
       " ['Sanitizes and has a nice scent.'],\n",
       " ['Havent used it.\\nWell packaged sha.'],\n",
       " ['Smells good too'],\n",
       " [\"It's serving well .\"]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the dataframe into a list \n",
    "comment_list = comments.values.tolist() \n",
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing Data \n",
    "import string \n",
    "from nltk.corpus import stopwords as sw \n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize \n",
    "from nltk import sent_tokenize \n",
    "from nltk import WordNetLemmatizer \n",
    "from nltk import pos_tag \n",
    "from nltk import RegexpTokenizer\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning or preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import nltk \n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\\'Great Quality\\'], [\\'Normal sanitizer. Does its job\\'], [\\'quite sticky, but it does the job\\'], [\\'Fits nicely in hand bags etc and reasonably priced. \\\\nGood product.\\'], [\\'We like am well well.\\'], [\\'its ok\\'], [\\'Sanitizes and has a nice scent.\\'], [\\'Havent used it.\\\\nWell packaged sha.\\'], [\\'Smells good too\\'], [\"It\\'s serving well .\"]]'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the list into string \n",
    "text_data = str(comment_list) \n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') \n",
    "en_stopwords = set(sw.words('english')) \n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text = [] \n",
    "def to_lower_case(data): \n",
    "    for words in text_data: \n",
    "        lower_text.append(str.lower(words))\n",
    "\n",
    "\n",
    "to_lower_case(text_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\\'Great Quality\\'], [\\'Normal sanitizer. Does its job\\'], [\\'quite sticky, but it does the job\\'], [\\'Fits nicely in hand bags etc and reasonably priced. \\\\nGood product.\\'], [\\'We like am well well.\\'], [\\'its ok\\'], [\\'Sanitizes and has a nice scent.\\'], [\\'Havent used it.\\\\nWell packaged sha.\\'], [\\'Smells good too\\'], [\"It\\'s serving well .\"]]'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\\'great quality\\'], [\\'normal sanitizer. does its job\\'], [\\'quite sticky, but it does the job\\'], [\\'fits nicely in hand bags etc and reasonably priced. \\\\ngood product.\\'], [\\'we like am well well.\\'], [\\'its ok\\'], [\\'sanitizes and has a nice scent.\\'], [\\'havent used it.\\\\nwell packaged sha.\\'], [\\'smells good too\\'], [\"it\\'s serving well .\"]]'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn the text into lower case \n",
    "clean_text1 = text_data.lower()\n",
    "clean_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[['great\",\n",
       " \"quality'],\",\n",
       " \"['normal\",\n",
       " 'sanitizer.',\n",
       " 'does',\n",
       " 'its',\n",
       " \"job'],\",\n",
       " \"['quite\",\n",
       " 'sticky,',\n",
       " 'but',\n",
       " 'it',\n",
       " 'does',\n",
       " 'the',\n",
       " \"job'],\",\n",
       " \"['fits\",\n",
       " 'nicely',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'bags',\n",
       " 'etc',\n",
       " 'and',\n",
       " 'reasonably',\n",
       " 'priced.',\n",
       " '\\\\ngood',\n",
       " \"product.'],\",\n",
       " \"['we\",\n",
       " 'like',\n",
       " 'am',\n",
       " 'well',\n",
       " \"well.'],\",\n",
       " \"['its\",\n",
       " \"ok'],\",\n",
       " \"['sanitizes\",\n",
       " 'and',\n",
       " 'has',\n",
       " 'a',\n",
       " 'nice',\n",
       " \"scent.'],\",\n",
       " \"['havent\",\n",
       " 'used',\n",
       " 'it.\\\\nwell',\n",
       " 'packaged',\n",
       " \"sha.'],\",\n",
       " \"['smells\",\n",
       " 'good',\n",
       " \"too'],\",\n",
       " '[\"it\\'s',\n",
       " 'serving',\n",
       " 'well',\n",
       " '.\"]]']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization \n",
    "\n",
    "clean_text_2 = clean_text1.split() \n",
    "clean_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'great\",\n",
       " \"quality'\",\n",
       " \"'normal\",\n",
       " 'sanitizer',\n",
       " 'does',\n",
       " 'its',\n",
       " \"job'\",\n",
       " \"'quite\",\n",
       " 'sticky',\n",
       " 'but',\n",
       " 'it',\n",
       " 'does',\n",
       " 'the',\n",
       " \"job'\",\n",
       " \"'fits\",\n",
       " 'nicely',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'bags',\n",
       " 'etc',\n",
       " 'and',\n",
       " 'reasonably',\n",
       " 'priced',\n",
       " 'ngood',\n",
       " 'product',\n",
       " \"'\",\n",
       " \"'we\",\n",
       " 'like',\n",
       " 'am',\n",
       " 'well',\n",
       " 'well',\n",
       " \"'\",\n",
       " \"'its\",\n",
       " \"ok'\",\n",
       " \"'sanitizes\",\n",
       " 'and',\n",
       " 'has',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'scent',\n",
       " \"'\",\n",
       " \"'havent\",\n",
       " 'used',\n",
       " 'it',\n",
       " 'nwell',\n",
       " 'packaged',\n",
       " 'sha',\n",
       " \"'\",\n",
       " \"'smells\",\n",
       " 'good',\n",
       " \"too'\",\n",
       " \"it's\",\n",
       " 'serving',\n",
       " 'well']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization using regular expression \n",
    "import re\n",
    "tokens_1 = re.findall(\"[\\w']+\",clean_text1)  \n",
    "tokens_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize(clean_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove symbols \n",
    "import re\n",
    "clean_text_2 = [] \n",
    "\n",
    "\n",
    "for words in tokens_1:\n",
    "    clean = []\n",
    "    #for w in words: \n",
    "    res = re.sub(r'[^A-Za-z0-9]+', \"\", words)\n",
    "    if res != \"\":\n",
    "        clean.append(res)\n",
    "    clean_text_2.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'quality',\n",
       " 'normal',\n",
       " 'sanitizer',\n",
       " 'does',\n",
       " 'its',\n",
       " 'job',\n",
       " 'quite',\n",
       " 'sticky',\n",
       " 'but',\n",
       " 'it',\n",
       " 'does',\n",
       " 'the',\n",
       " 'job',\n",
       " 'fits',\n",
       " 'nicely',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'bags',\n",
       " 'etc',\n",
       " 'and',\n",
       " 'reasonably',\n",
       " 'priced',\n",
       " 'ngood',\n",
       " 'product',\n",
       " '',\n",
       " 'we',\n",
       " 'like',\n",
       " 'am',\n",
       " 'well',\n",
       " 'well',\n",
       " '',\n",
       " 'its',\n",
       " 'ok',\n",
       " 'sanitizes',\n",
       " 'and',\n",
       " 'has',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'scent',\n",
       " '',\n",
       " 'havent',\n",
       " 'used',\n",
       " 'it',\n",
       " 'nwell',\n",
       " 'packaged',\n",
       " 'sha',\n",
       " '',\n",
       " 'smells',\n",
       " 'good',\n",
       " 'too',\n",
       " 'its',\n",
       " 'serving',\n",
       " 'well']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word removal \n",
    "clean_text_3 = [] \n",
    "\n",
    "for words in clean_text_2:\n",
    "    w = []\n",
    "    for word in words: \n",
    "        if word not in sw.words('english'):\n",
    "            w.append(word)\n",
    "            clean_text_3.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'quality',\n",
       " 'normal',\n",
       " 'sanitizer',\n",
       " 'job',\n",
       " 'quite',\n",
       " 'sticky',\n",
       " 'job',\n",
       " 'fits',\n",
       " 'nicely',\n",
       " 'hand',\n",
       " 'bags',\n",
       " 'etc',\n",
       " 'reasonably',\n",
       " 'priced',\n",
       " 'ngood',\n",
       " 'product',\n",
       " '',\n",
       " 'like',\n",
       " 'well',\n",
       " 'well',\n",
       " '',\n",
       " 'ok',\n",
       " 'sanitizes',\n",
       " 'nice',\n",
       " 'scent',\n",
       " '',\n",
       " 'havent',\n",
       " 'used',\n",
       " 'nwell',\n",
       " 'packaged',\n",
       " 'sha',\n",
       " '',\n",
       " 'smells',\n",
       " 'good',\n",
       " 'serving',\n",
       " 'well']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sw.words('english')\n",
    "stop_words = set(sw.words('english'))\n",
    "filtered_word = [] \n",
    "for w in clean_text_2: \n",
    "    if w not in stop_words: \n",
    "        filtered_word.append(w)\n",
    "\n",
    "\n",
    "filtered_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'qualiti',\n",
       " 'normal',\n",
       " 'sanit',\n",
       " 'job',\n",
       " 'quit',\n",
       " 'sticki',\n",
       " 'job',\n",
       " 'fit',\n",
       " 'nice',\n",
       " 'hand',\n",
       " 'bag',\n",
       " 'etc',\n",
       " 'reason',\n",
       " 'price',\n",
       " 'ngood',\n",
       " 'product',\n",
       " '',\n",
       " 'like',\n",
       " 'well',\n",
       " 'well',\n",
       " '',\n",
       " 'ok',\n",
       " 'sanit',\n",
       " 'nice',\n",
       " 'scent',\n",
       " '',\n",
       " 'havent',\n",
       " 'use',\n",
       " 'nwell',\n",
       " 'packag',\n",
       " 'sha',\n",
       " '',\n",
       " 'smell',\n",
       " 'good',\n",
       " 'serv',\n",
       " 'well']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming: this is used to remove the prefix/suffix of a word or make a word it root form  \n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stem_words = []\n",
    "port = PorterStemmer()\n",
    "for w in filtered_word: \n",
    "    rootWord = ps.stem(w)\n",
    "    stem_words.append(rootWord)\n",
    "\n",
    "\n",
    "\n",
    "stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'quality',\n",
       " 'normal',\n",
       " 'sanitizer',\n",
       " 'job',\n",
       " 'quite',\n",
       " 'sticky',\n",
       " 'job',\n",
       " 'fit',\n",
       " 'nicely',\n",
       " 'hand',\n",
       " 'bag',\n",
       " 'etc',\n",
       " 'reasonably',\n",
       " 'price',\n",
       " 'ngood',\n",
       " 'product',\n",
       " '',\n",
       " 'like',\n",
       " 'well',\n",
       " 'well',\n",
       " '',\n",
       " 'ok',\n",
       " 'sanitize',\n",
       " 'nice',\n",
       " 'scent',\n",
       " '',\n",
       " 'havent',\n",
       " 'use',\n",
       " 'nwell',\n",
       " 'package',\n",
       " 'sha',\n",
       " '',\n",
       " 'smell',\n",
       " 'good',\n",
       " 'serve',\n",
       " 'well']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma_words = []\n",
    "wordnet_lemmatizer = WordNetLemmatizer() \n",
    "for w in filtered_word: \n",
    "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
    "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
    "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
    "    lemma_words.append(word3)\n",
    "\n",
    "\n",
    "\n",
    "lemma_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "def NaiveBaiyes_Sentimental(word):\n",
    "    blob = TextBlob(word, analyzer=NaiveBayesAnalyzer())\n",
    "    NaiveBayes_SentimentScore=blob.sentiment.classification\n",
    "    return NaiveBayes_SentimentScore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['great', 'quality', 'normal', 'sanitizer', 'job', 'quite', 'sticky', 'job', 'fit', 'nicely', 'hand', 'bag', 'etc', 'reasonably', 'price', 'ngood', 'product', '', 'like', 'well', 'well', '', 'ok', 'sanitize', 'nice', 'scent', '', 'havent', 'use', 'nwell', 'package', 'sha', '', 'smell', 'good', 'serve', 'well']\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_data = str(lemma_words) \n",
    "string_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the string of data where 'pos' = positive(1.0), 'neg'(0.0) = negative, 'neu' = neural \n",
    "NaiveBaiyes_Sentimental(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(word): \n",
    "    def getSubjectivity(text): \n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "#create a function to get the polarity \n",
    "    def getPolarity(text): \n",
    "        return TextBlob(text).sentiment.polarity \n",
    "#create two new columns 'subjectivity' and 'polarity'  \n",
    "    #word['TextBlob_Subjectivity'] = word['word'].apply(getSubjectivity)\n",
    "    #word['TextBlob_Polarity'] = word['word'].apply(getPolarity)\n",
    "    #def getAnalysis(score): \n",
    "        #if score < 0: \n",
    "            #return 'Negative'\n",
    "        #elif score == 0: \n",
    "            #return 'Neutral'\n",
    "        #else: \n",
    "            #return 'positive'\n",
    "        #word['TextBlob_Analysis'] = word['TextBlob_Polarity'].apply(getAnalysis)\n",
    "        #return word \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data \n",
    "\n",
    "y_train = [1,1,1,1,1,0,0,0,0,0] #1 = Positive, #0 = Negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many times a word appear in the array it is also called bagofwords model \n",
    "cv = CountVectorizer(ngram_range=(1,1))\n",
    "x_vec = cv.fit_transform(lemma_words).toarray()#convert the text into array \n",
    "\n",
    "x_vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bag', 'etc', 'fit', 'good', 'great', 'hand', 'havent', 'job', 'like', 'ngood', 'nice', 'nicely', 'normal', 'nwell', 'ok', 'package', 'price', 'product', 'quality', 'quite', 'reasonably', 'sanitize', 'sanitizer', 'scent', 'serve', 'sha', 'smell', 'sticky', 'use', 'well']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_vect = cv.transform(lemma_words).toarray()\n",
    "\n",
    "xt_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Multinomial Naive Bayes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_vec, lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 30)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mn = MultinomialNB()\n",
    "#mn.fit(x_vec, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "senti = SentimentIntensityAnalyzer()\n",
    "print(senti.polarity_scores('good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
